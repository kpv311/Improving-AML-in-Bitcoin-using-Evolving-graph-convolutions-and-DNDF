{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilayer perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxdaNlmAEFYd"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly.offline as py \n",
        "import plotly.graph_objs as go \n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_TSg1xKFdiP"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"karthikapv\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"cc11b8fcbb2e177d31cd566bbabe382a\" # key from the json file\n",
        "!kaggle datasets download -d ellipticco/elliptic-data-set\n",
        "!unzip elliptic-data-set.zip\n",
        "!mkdir elliptic_bitcoin_dataset_cont"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ0ebD61FUHE"
      },
      "source": [
        "edges = pd.read_csv(\"elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\n",
        "features = pd.read_csv(\"elliptic_bitcoin_dataset/elliptic_txs_features.csv\",header=None)\n",
        "classes = pd.read_csv(\"elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KIZfMqhF3yV"
      },
      "source": [
        "tx_features = [\"tx_feat_\"+str(i) for i in range(2,95)]\n",
        "agg_features = [\"agg_feat_\"+str(i) for i in range(1,73)]\n",
        "features.columns = [\"txId\",\"time_step\"] + tx_features + agg_features\n",
        "features = pd.merge(features,classes,left_on=\"txId\",right_on=\"txId\",how='left')\n",
        "features['class'] = features['class'].apply(lambda x: '0' if x == \"unknown\" else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYxilvw1F7ZL"
      },
      "source": [
        "count_by_class = features[[\"time_step\",'class']].groupby(['time_step','class']).size().to_frame().reset_index()\n",
        "illicit_count = count_by_class[count_by_class['class'] == '1']\n",
        "licit_count = count_by_class[count_by_class['class'] == '2']\n",
        "unknown_count = count_by_class[count_by_class['class'] == \"0\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ltsRE3WGC8G"
      },
      "source": [
        "data = features[(features['class']=='1') | (features['class']=='2')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCHdXOetGLK7"
      },
      "source": [
        "X = data[tx_features+agg_features]\n",
        "y = data['class']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYu9wCagGNJt"
      },
      "source": [
        "class LoadData(Dataset):\n",
        "\n",
        "    def __init__(self,X,y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        features = self.X.iloc[idx]\n",
        "        features = np.array([features])\n",
        "        label = y.iloc[idx]\n",
        "\n",
        "        return features,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzsTYolGSsE"
      },
      "source": [
        "traindata = LoadData(X_train,y_train)\n",
        "train_loader = DataLoader(traindata,batch_size=128,shuffle=True)  \n",
        "\n",
        "testdata = LoadData(X_test,y_test)\n",
        "test_loader = DataLoader(testdata,batch_size=128,shuffle=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_7mPVqZGVN0"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden = nn.Linear(165,50 )\n",
        "\n",
        "        self.output = nn.Linear(50,1)\n",
        "        self.out = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.hidden(x))\n",
        "\n",
        "        x = self.out(self.output(x))\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Za9XDdGYui"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion=nn.BCELoss()\n",
        "n_epochs=25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fD_IPpkGaye"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "        model.to('cuda')\n",
        "        model.train()\n",
        "        running_loss = 0.\n",
        "        for data in train_loader:\n",
        "            x,label=data\n",
        "            x,label=x.cuda(),label.cuda()\n",
        "            output = model.forward(x.float())\n",
        "            output = output.squeeze()\n",
        "            loss = criterion(output.float(), label.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        else:\n",
        "            print(f\"Training loss: {running_loss/len(train_loader)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-klibytGeXj"
      },
      "source": [
        "all_preds = []\n",
        "for data in test_loader:\n",
        "    x,labels = data\n",
        "    x,labels = x.cuda(),labels.cuda()\n",
        "    model.to('cuda')\n",
        "    preds = model.forward(x.float())\n",
        "    all_preds.extend(preds.squeeze().detach().cpu().numpy())\n",
        "\n",
        "preds = pd.Series(all_preds).apply(lambda x: round(x))\n",
        "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
        "print(\"MLP - All features\")\n",
        "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
        "micro_f1 = f1_score(y_test,preds,average='micro')\n",
        "print(\"Micro-Average F1 Score:\",micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbU8fxdeyDOu"
      },
      "source": [
        "count_by_class = features[[\"time_step\",'class']].groupby(['time_step','class']).size().to_frame().reset_index()\n",
        "illicit_count = count_by_class[count_by_class['class'] == '1']\n",
        "licit_count = count_by_class[count_by_class['class'] == '2']\n",
        "unknown_count = count_by_class[count_by_class['class'] == \"0\"]\n",
        "data = features[(features['class']=='1') | (features['class']=='2')]\n",
        "X = data[tx_features]\n",
        "y = data['class']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT_SoiwKyLkl"
      },
      "source": [
        "class LoadData(Dataset):\n",
        "\n",
        "    def __init__(self,X,y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        features = self.X.iloc[idx]\n",
        "        features = np.array([features])\n",
        "        label = y.iloc[idx]\n",
        "\n",
        "        return features,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh6VO816yQgw"
      },
      "source": [
        "traindata = LoadData(X_train,y_train)\n",
        "train_loader = DataLoader(traindata,batch_size=128,shuffle=True)  \n",
        "\n",
        "testdata = LoadData(X_test,y_test)\n",
        "test_loader = DataLoader(testdata,batch_size=128,shuffle=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfxk2VoFyVOC"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden = nn.Linear(93,40 )\n",
        "\n",
        "        self.output = nn.Linear(40,1)\n",
        "        self.out = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.hidden(x))\n",
        "\n",
        "        x = self.out(self.output(x))\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYw9NHb9yZ7m"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion=nn.BCELoss()\n",
        "n_epochs=25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdmDdocwydes"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "        model.to('cuda')\n",
        "        model.train()\n",
        "        running_loss = 0.\n",
        "        for data in train_loader:\n",
        "            x,label=data\n",
        "            x,label=x.cuda(),label.cuda()\n",
        "            output = model.forward(x.float())\n",
        "            output = output.squeeze()\n",
        "            loss = criterion(output.float(), label.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        else:\n",
        "            print(f\"Training loss: {running_loss/len(train_loader)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umfOlLlx_Tgb"
      },
      "source": [
        "all_preds = []\n",
        "for data in test_loader:\n",
        "    x,labels = data\n",
        "    x,labels = x.cuda(),labels.cuda()\n",
        "    model.to('cuda')\n",
        "    preds = model.forward(x.float())\n",
        "    all_preds.extend(preds.squeeze().detach().cpu().numpy())\n",
        "\n",
        "preds = pd.Series(all_preds).apply(lambda x: round(x))\n",
        "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
        "print(\"MLP - Local features\")\n",
        "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
        "micro_f1 = f1_score(y_test,preds,average='micro')\n",
        "print(\"Micro-Average F1 Score:\",micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDrAlj_YMxqB"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"karthikapv\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"cc11b8fcbb2e177d31cd566bbabe382a\" # key from the json file\n",
        "!kaggle datasets download -d dhruvrnaik/ellipticemb50d\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4-xqZjCNU4e"
      },
      "source": [
        "!unzip ellipticemb50d.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kynyI-fgJGEO"
      },
      "source": [
        "embed_names = [\"emb_\"+str(i) for i in range(1,51)]\n",
        "embeddings = pd.read_csv('elliptic.emb',delimiter=\" \",skiprows=1,header=None)\n",
        "embeddings.columns = ['txId'] + [\"emb_\"+str(i) for i in range(1,51)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2B_f5FLKgVx"
      },
      "source": [
        "data = features[(features['class']=='1') | (features['class']=='2')]\n",
        "data = pd.merge(data,embeddings,how='inner')\n",
        "X = data[tx_features+agg_features+embed_names]\n",
        "y = data['class']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbdbgspAKhKR"
      },
      "source": [
        "traindata = LoadData(X_train,y_train)\n",
        "train_loader = DataLoader(traindata,batch_size=128,shuffle=True)  \n",
        "\n",
        "testdata = LoadData(X_test,y_test)\n",
        "test_loader = DataLoader(testdata,batch_size=128,shuffle=False)  \n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden = nn.Linear(215,50 )\n",
        "\n",
        "        self.output = nn.Linear(50,1)\n",
        "        self.out = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden(x))\n",
        "\n",
        "        x = self.out(self.output(x))\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiiLSoYzKqGo"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion=nn.BCELoss()\n",
        "n_epochs=25\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "        model.to('cuda')\n",
        "        model.train()\n",
        "        running_loss = 0.\n",
        "        for data in train_loader:\n",
        "            x,label=data\n",
        "            x,label=x.cuda(),label.cuda()\n",
        "            output = model.forward(x.float())\n",
        "            output = output.squeeze()\n",
        "            loss = criterion(output.float(), label.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        else:\n",
        "            print(f\"Training loss: {running_loss/len(train_loader)}\")\n",
        "            all_preds = []\n",
        "for data in test_loader:\n",
        "    x,labels = data\n",
        "    x,labels = x.cuda(),labels.cuda()\n",
        "    preds = model.forward(x.float())\n",
        "    all_preds.extend(preds.squeeze().detach().cpu().numpy())\n",
        "\n",
        "preds = pd.Series(all_preds).apply(lambda x: round(x))\n",
        "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
        "print(\"MLP- All features + node embeddings\")\n",
        "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
        "micro_f1 = f1_score(y_test,preds,average='micro')\n",
        "print(\"Micro-Average F1 Score:\",micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziFTVnxY_lMV"
      },
      "source": [
        "data = features[(features['class']=='1') | (features['class']=='2')]\n",
        "data = pd.merge(data,embeddings,how='inner')\n",
        "X = data[tx_features+embed_names]\n",
        "y = data['class']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxITUWZ0_mEy"
      },
      "source": [
        "traindata = LoadData(X_train,y_train)\n",
        "train_loader = DataLoader(traindata,batch_size=128,shuffle=True)  \n",
        "\n",
        "testdata = LoadData(X_test,y_test)\n",
        "test_loader = DataLoader(testdata,batch_size=128,shuffle=False)  \n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden = nn.Linear(143,40 )\n",
        "\n",
        "        self.output = nn.Linear(40,1)\n",
        "        self.out = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.hidden(x))\n",
        "\n",
        "        x = self.out(self.output(x))\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me49Kb4f_tAc"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion=nn.BCELoss()\n",
        "n_epochs=25\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "        model.to('cuda')\n",
        "        model.train()\n",
        "        running_loss = 0.\n",
        "        for data in train_loader:\n",
        "            x,label=data\n",
        "            x,label=x.cuda(),label.cuda()\n",
        "            output = model.forward(x.float())\n",
        "            output = output.squeeze()\n",
        "            loss = criterion(output.float(), label.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        else:\n",
        "            print(f\"Training loss: {running_loss/len(train_loader)}\")\n",
        "            all_preds = []\n",
        "for data in test_loader:\n",
        "    x,labels = data\n",
        "    x,labels = x.cuda(),labels.cuda()\n",
        "    preds = model.forward(x.float())\n",
        "    all_preds.extend(preds.squeeze().detach().cpu().numpy())\n",
        "\n",
        "preds = pd.Series(all_preds).apply(lambda x: round(x))\n",
        "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
        "print(\"MLP- Local features + node embeddings\")\n",
        "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
        "micro_f1 = f1_score(y_test,preds,average='micro')\n",
        "print(\"Micro-Average F1 Score:\",micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOZ6W1Y0BXie"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}