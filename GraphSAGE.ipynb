{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphSAGE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6FNphu5_pGX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import random\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2xGGdhjHugU"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"parvathisankar214\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"6ad0a24e1cf702c8069fd273e296474b\" # key from the json file\n",
        "!kaggle datasets download -d ellipticco/elliptic-data-set\n",
        "!unzip elliptic-data-set.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5rgJKWjH1Ty"
      },
      "source": [
        "feature_df = pd.read_csv('/content/elliptic_bitcoin_dataset/elliptic_txs_features.csv', header=None)\n",
        "class_df = pd.read_csv('/content/elliptic_bitcoin_dataset/elliptic_txs_classes.csv', header=None)\n",
        "edgelist_df = pd.read_csv('/content/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNeubk_MH5hh"
      },
      "source": [
        "print(feature_df.values.tolist()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU8yuJG0AJ36"
      },
      "source": [
        "def load_data():\n",
        "    feature=feature_df\n",
        "    record_num=feature.shape[0]\n",
        "    feature_num= 165\n",
        "    nodes_num=record_num+1\n",
        "\n",
        "    m_feature=np.zeros((nodes_num,feature_num))\n",
        "    labels=np.zeros((nodes_num,1))\n",
        "    \n",
        "   \n",
        "    node2idx={}  #node2idx[paper_id]->index\n",
        "    label2idx={}\n",
        "\n",
        "    for i, data in enumerate(zip(feature_df.values.tolist(), class_df.values.tolist()[1:])):\n",
        "        m_feature[i,:]=data[0][2:]\n",
        "        node2idx[data[0][0]]=i\n",
        "        class_ = data[1]\n",
        "        if class_[-1] not in label2idx.keys():\n",
        "            label2idx[class_[-1]]=len(label2idx)\n",
        "        labels[i]=label2idx[class_[-1]]\n",
        "\n",
        "    adj=defaultdict(set)\n",
        "    for row in edgelist_df.values.tolist() :\n",
        "        a,b=node2idx[row[0]],node2idx[row[1]]\n",
        "        adj[a].add(b)\n",
        "        adj[b].add(a)\n",
        "\n",
        "    return m_feature,labels,adj\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT81I20KLzBy"
      },
      "source": [
        "class Aggregator(nn.Module):\n",
        "    def __init__(self,features,aggr_method=\"mean\"):\n",
        "     \n",
        "        super(Aggregator,self).__init__()\n",
        "        self.features=features\n",
        "        self.aggr_method=aggr_method\n",
        "    \n",
        "    def forward(self,nodes,neighs,num_sample=10):\n",
        "  \n",
        "        result=[]\n",
        "        for i,adj_node in enumerate(neighs):\n",
        "            if len(adj_node)>=num_sample:\n",
        "                temp=random.sample(list(adj_node),num_sample)\n",
        "            else:\n",
        "                temp=adj_node\n",
        "            result.append(set(temp))\n",
        "        '''\n",
        "        result=[]\n",
        "        for i,adj_node in enumerate(neighs):\n",
        "            temp=np.random.choice(list(adj_node),num_sampleï¼Œreplacement=True)\n",
        "            result.append(set(temp))\n",
        "        '''\n",
        "  \n",
        "        unique_nodes_list=list(set.union(*result))\n",
        "        unique_nodes={n:i for i,n in enumerate(unique_nodes_list)}\n",
        "    \n",
        "        mask = Variable(torch.zeros(len(result), len(unique_nodes)))\n",
        "        column_indices = [unique_nodes[n] for temp in result for n in temp]   \n",
        "        row_indices = [i for i in range(len(result)) for j in range(len(result[i]))]\n",
        "        mask[row_indices, column_indices] = 1\n",
        "        if(self.aggr_method==\"mean\"):\n",
        "            num_neigh = mask.sum(1, keepdim=True)\n",
        "            mask = mask.div(num_neigh)\n",
        "        if(self.aggr_method==\"sum\"):\n",
        "            mask=mask\n",
        "  \n",
        "        embed_matrix = self.features(torch.LongTensor(unique_nodes_list))\n",
        "        print(embed_matrix.shape)\n",
        "        feats = mask.mm(embed_matrix)\n",
        "        return feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21j-GBYoARVb"
      },
      "source": [
        "class GraphSage(nn.Module):\n",
        "    def __init__(self,features,adj_table,input_dim,embed_dim,aggregator,num_sample=10):\n",
        "        super(GraphSage,self).__init__()\n",
        "        \n",
        "        self.features=features\n",
        "        self.aggregator=aggregator\n",
        "        self.num_sample=num_sample\n",
        "        self.adj_table=adj_table\n",
        "        self.input_dim=input_dim\n",
        "        self.embed_dim=embed_dim\n",
        "        \n",
        "        self.weight=nn.Parameter(torch.FloatTensor(embed_dim,2*input_dim))\n",
        "        init.xavier_uniform_(self.weight)\n",
        "    \n",
        "    def forward(self,nodes):\n",
        "\n",
        "        neighs=[]\n",
        "        for node in nodes:\n",
        "            neighs.append(self.adj_table[node])\n",
        "        n_feature=self.aggregator.forward(nodes,neighs,self.num_sample)\n",
        "        self_feature=self.features(torch.LongTensor(nodes))\n",
        "        combined=torch.cat([self_feature,n_feature],dim=1)\n",
        "        \n",
        "        return F.relu(self.weight.mm(combined.t()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNqgwua_AT9x"
      },
      "source": [
        "def data_split(num_nodes):\n",
        "    random_idx=np.random.permutation(num_nodes)\n",
        "    train,val=random_idx[:int(num_nodes/10*9)],random_idx[int(num_nodes/10*9):]\n",
        "    return train,val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zog08LxeAV2Z"
      },
      "source": [
        "class predict(nn.Module):\n",
        "    def __init__(self,model,num_class):\n",
        "        super(predict,self).__init__()\n",
        "        self.model=model\n",
        "        self.weight=nn.Parameter(torch.FloatTensor(num_classes,model.embed_dim))\n",
        "    \n",
        "        init.xavier_uniform_(self.weight)\n",
        "    \n",
        "    def forward(self,nodes):\n",
        "\n",
        "        hidden=self.model(nodes)\n",
        "        return self.weight.mm(hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzG34499AX2f"
      },
      "source": [
        "def early_stop(accuracy_list,index,difference):\n",
        "    if index>=1:\n",
        "        if((accuracy_list[index-1]-accuracy_list[index])>difference):\n",
        "            return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsKD8gl1AZ6f"
      },
      "source": [
        "def accuracy(labels,predict):\n",
        "\n",
        "    case=0\n",
        "    node_num=labels.shape[0]\n",
        "    for i,classes in enumerate(labels):\n",
        "        if(labels[i]==predict[i]):\n",
        "            case=case+1\n",
        "    return case/node_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU1zdBbVAbn2"
      },
      "source": [
        "batch_size=300\n",
        "embedding_dim=128\n",
        "learning_rate=0.001\n",
        "difference=0.05\n",
        "epoch=200\n",
        "num_classes=3\n",
        "features_data,labels,adj_table=load_data()\n",
        "(a,b)=features_data.shape\n",
        "\n",
        "features=nn.Embedding(a,b)\n",
        "features.weight=nn.Parameter(torch.FloatTensor(features_data),requires_grad=False)\n",
        "\n",
        "aggregator=Aggregator(features,aggr_method=\"sum\")\n",
        "Layer=GraphSage(features,adj_table,b,embedding_dim,aggregator)\n",
        "\n",
        "\n",
        "predict_classes=predict(Layer, num_classes)\n",
        "\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(predict_classes.parameters(),lr=learning_rate)\n",
        "\n",
        "\n",
        "train,val=data_split(int(a))\n",
        "\n",
        "epoch_record=[]\n",
        "loss_record=[]\n",
        "accuracy_record=[]\n",
        "micro_f1=[]\n",
        "illicit_f1_arr = []\n",
        "for i in range(epoch):\n",
        "    random.shuffle(train)\n",
        "    nodes=train[:batch_size]\n",
        "    optimizer.zero_grad()\n",
        "    predict_result=predict_classes(nodes).t()\n",
        "    loss=loss_fn(predict_result,torch.LongTensor(labels[nodes].squeeze()))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(\"epoch:\",i,\"loss:\",loss.item())\n",
        "    epoch_record.append(i)\n",
        "    loss_record.append(loss.item())\n",
        "    accuracy_record.append(accuracy(labels[val].squeeze(),predict_classes(val).data.numpy().argmax(axis=0)))\n",
        "    #illicit_f1_arr.append(f1_score(labels[val].squeeze(),predict_classes(val).data.numpy().argmax(axis=0),average=None))\n",
        "    micro_f1.append(f1_score(labels[val].squeeze(),predict_classes(val).data.numpy().argmax(axis=0),average=\"micro\"))\n",
        "    if(early_stop(accuracy_record,i,difference)==True):\n",
        "        break\n",
        "    \n",
        "ground_truth=labels[val].squeeze()\n",
        "final_predict=predict_classes(val).data.numpy().argmax(axis=0)\n",
        "print(\"Accuracy:\",accuracy(ground_truth,final_predict))\n",
        "print(\"F1 score:\",f1_score(ground_truth,final_predict,average=\"micro\"))\n",
        "print(\"Current epoch:\",i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyTGWuAQRFkW"
      },
      "source": [
        "plt.plot(epoch_record,loss_record,marker='o',color='green')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss of training set\")\n",
        "plt.legend([\"loss\"])\n",
        "plt.show()\n",
        "plt.plot(epoch_record,accuracy_record,color='black')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend([\"accuracy\"])\n",
        "plt.show()\n",
        "plt.plot(epoch_record,micro_f1,color='orange')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"F1\")\n",
        "plt.legend([\"F1\"])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}