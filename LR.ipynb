{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAZL388ADqqw"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly.offline as py \n",
        "import plotly.graph_objs as go \n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOFUOUc0D2hp"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"karthikapv\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"cc11b8fcbb2e177d31cd566bbabe382a\" # key from the json file\n",
        "!kaggle datasets download -d ellipticco/elliptic-data-set\n",
        "!unzip elliptic-data-set.zip\n",
        "!mkdir elliptic_bitcoin_dataset_cont"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q17sC0FRD9TB"
      },
      "source": [
        "edges = pd.read_csv(\"elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\n",
        "features = pd.read_csv(\"elliptic_bitcoin_dataset/elliptic_txs_features.csv\",header=None)\n",
        "classes = pd.read_csv(\"elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MfXlVAAEAHI"
      },
      "source": [
        "tx_features = [\"tx_feat_\"+str(i) for i in range(2,95)]\n",
        "agg_features = [\"agg_feat_\"+str(i) for i in range(1,73)]\n",
        "features.columns = [\"txId\",\"time_step\"] + tx_features + agg_features\n",
        "features = pd.merge(features,classes,left_on=\"txId\",right_on=\"txId\",how='left')\n",
        "features['class'] = features['class'].apply(lambda x: '0' if x == \"unknown\" else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ8OC72nECcl"
      },
      "source": [
        "count_by_class = features[[\"time_step\",'class']].groupby(['time_step','class']).size().to_frame().reset_index()\n",
        "illicit_count = count_by_class[count_by_class['class'] == '1']\n",
        "licit_count = count_by_class[count_by_class['class'] == '2']\n",
        "unknown_count = count_by_class[count_by_class['class'] == \"0\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVgrjWpQEFYh"
      },
      "source": [
        "data = features[(features['class']=='1') | (features['class']=='2')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXfT0J4EEH5m"
      },
      "source": [
        "X = data[tx_features+agg_features]\n",
        "y = data['class']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,shuffle=False)\n",
        "reg = LogisticRegression().fit(X_train,y_train)\n",
        "preds = reg.predict(X_test)\n",
        "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
        "print(\"Logistic Regression-All features\")\n",
        "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
        "micro_f1 = f1_score(y_test,preds,average='micro')\n",
        "print(\"Micro-Average F1 Score:\",micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOjJj0wtETes"
      },
      "source": [
        "data = features[(features['class']=='1') | (features['class']=='2')]\n",
        "X = data[tx_features]\n",
        "y = data['class']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,shuffle=False)\n",
        "reg = LogisticRegression().fit(X_train,y_train)\n",
        "preds = reg.predict(X_test)\n",
        "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
        "print(\"Logistic Regression-Local features\")\n",
        "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
        "micro_f1 = f1_score(y_test,preds,average='micro')\n",
        "print(\"Micro-Average F1 Score:\",micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWAxx_QMEWNB"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"karthikapv\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"cc11b8fcbb2e177d31cd566bbabe382a\" # key from the json file\n",
        "!kaggle datasets download -d dhruvrnaik/ellipticemb50d\n",
        "!unzip ellipticemb50d.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2-rKfWFEbe-"
      },
      "source": [
        "embed_names = [\"emb_\"+str(i) for i in range(1,51)]\n",
        "embeddings = pd.read_csv('elliptic.emb',delimiter=\" \",skiprows=1,header=None)\n",
        "embeddings.columns = ['txId'] + [\"emb_\"+str(i) for i in range(1,51)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snf0e7oxEiGt"
      },
      "source": [
        "data = features[(features['class']=='1') | (features['class']=='2')]\n",
        "data = pd.merge(data,embeddings,how='inner')\n",
        "X = data[tx_features+agg_features+embed_names]\n",
        "y = data['class']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,shuffle=False)\n",
        "reg = LogisticRegression().fit(X_train,y_train)\n",
        "preds = reg.predict(X_test)\n",
        "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
        "print(\"Logistic Regression - All features + node embeddings\")\n",
        "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
        "micro_f1 = f1_score(y_test,preds,average='micro')\n",
        "print(\"Micro-Average F1 Score:\",micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2HWohLtEmia"
      },
      "source": [
        "data = features[(features['class']=='1') | (features['class']=='2')]\n",
        "data = pd.merge(data,embeddings,how='inner')\n",
        "X = data[tx_features+embed_names]\n",
        "y = data['class']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,shuffle=False)\n",
        "reg = LogisticRegression().fit(X_train,y_train)\n",
        "preds = reg.predict(X_test)\n",
        "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
        "print(\"Logistic Regression - Local features + node embeddings\")\n",
        "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
        "micro_f1 = f1_score(y_test,preds,average='micro')\n",
        "print(\"Micro-Average F1 Score:\",micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LKHPVpMEtYw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}